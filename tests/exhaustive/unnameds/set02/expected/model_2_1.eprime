language ESSENCE' 1.0

given n: int
find s_ExplicitVarSizeWithDummy: matrix indexed by [int(1..1 + (n - 1))] of int(1..n + 1)
find s_Occurrence: matrix indexed by [int(1..n)] of bool
such that
    and([[or([s_ExplicitVarSizeWithDummy[q12] != n + 1 /\ s_ExplicitVarSizeWithDummy[q12] = q3
                  | q12 : int(1..1 + (n - 1))])
              | q2 : int(1..n), q3 : int(1..n), q2 = q1 -> q3 = q1 + 1, q2 = q1 + 1 -> q3 = q1,
                q2 != q1 /\ q2 != q1 + 1 -> q3 = q2]
         <=lex
         [or([s_ExplicitVarSizeWithDummy[q14] != n + 1 /\ s_ExplicitVarSizeWithDummy[q14] = q2
                  | q14 : int(1..1 + (n - 1))])
              | q2 : int(1..n)]
             | q1 : int(1..n - 1)]),
    and([s_ExplicitVarSizeWithDummy[q1] < s_ExplicitVarSizeWithDummy[q1 + 1] \/ s_ExplicitVarSizeWithDummy[q1] = n + 1
             | q1 : int(1..1 + (n - 1) - 1)]),
    and([s_ExplicitVarSizeWithDummy[q2] = n + 1 -> s_ExplicitVarSizeWithDummy[q2 + 1] = n + 1
             | q2 : int(1..1 + (n - 1) - 1)]),
    and([s_Occurrence[q6] ->
         or([s_ExplicitVarSizeWithDummy[q8] != n + 1 /\ s_ExplicitVarSizeWithDummy[q8] = q6 | q8 : int(1..1 + (n - 1))])
             | q6 : int(1..n)]),
    and([s_ExplicitVarSizeWithDummy[q10] != n + 1 -> s_Occurrence[s_ExplicitVarSizeWithDummy[q10]]
             | q10 : int(1..1 + (n - 1))])

