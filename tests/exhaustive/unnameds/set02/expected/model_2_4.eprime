language ESSENCE' 1.0

given n: int
find s_ExplicitVarSizeWithDummy: matrix indexed by [int(1..1 + (n - 1))] of int(1..n + 1)
find s_ExplicitVarSizeWithFlags_Flags: matrix indexed by [int(1..1 + (n - 1))] of bool
find s_ExplicitVarSizeWithFlags_Values: matrix indexed by [int(1..1 + (n - 1))] of int(1..n)
such that
    and([[or([s_ExplicitVarSizeWithDummy[q19] != n + 1 /\ s_ExplicitVarSizeWithDummy[q19] = q3
                  | q19 : int(1..1 + (n - 1))])
              | q2 : int(1..n), q3 : int(1..n), q2 = q1 -> q3 = q1 + 1, q2 = q1 + 1 -> q3 = q1,
                q2 != q1 /\ q2 != q1 + 1 -> q3 = q2]
         <=lex
         [or([s_ExplicitVarSizeWithDummy[q21] != n + 1 /\ s_ExplicitVarSizeWithDummy[q21] = q2
                  | q21 : int(1..1 + (n - 1))])
              | q2 : int(1..n)]
             | q1 : int(1..n - 1)]),
    and([s_ExplicitVarSizeWithDummy[q1] < s_ExplicitVarSizeWithDummy[q1 + 1] \/ s_ExplicitVarSizeWithDummy[q1] = n + 1
             | q1 : int(1..1 + (n - 1) - 1)]),
    and([s_ExplicitVarSizeWithDummy[q2] = n + 1 -> s_ExplicitVarSizeWithDummy[q2 + 1] = n + 1
             | q2 : int(1..1 + (n - 1) - 1)]),
    and([s_ExplicitVarSizeWithFlags_Flags[q5 + 1] ->
         s_ExplicitVarSizeWithFlags_Values[q5] < s_ExplicitVarSizeWithFlags_Values[q5 + 1]
             | q5 : int(1..1 + (n - 1) - 1)]),
    and([s_ExplicitVarSizeWithFlags_Flags[q6] = false -> s_ExplicitVarSizeWithFlags_Values[q6] = 1
             | q6 : int(1..1 + (n - 1))]),
    and([s_ExplicitVarSizeWithFlags_Flags[q7 + 1] -> s_ExplicitVarSizeWithFlags_Flags[q7]
             | q7 : int(1..1 + (n - 1) - 1)]),
    and([s_ExplicitVarSizeWithFlags_Flags[q11] ->
         or([s_ExplicitVarSizeWithDummy[q13] != n + 1 /\
             s_ExplicitVarSizeWithDummy[q13] = s_ExplicitVarSizeWithFlags_Values[q11]
                 | q13 : int(1..1 + (n - 1))])
             | q11 : int(1..1 + (n - 1))]),
    and([s_ExplicitVarSizeWithDummy[q15] != n + 1 ->
         or([s_ExplicitVarSizeWithFlags_Flags[q17] /\
             s_ExplicitVarSizeWithFlags_Values[q17] = s_ExplicitVarSizeWithDummy[q15]
                 | q17 : int(1..1 + (n - 1))])
             | q15 : int(1..1 + (n - 1))])

