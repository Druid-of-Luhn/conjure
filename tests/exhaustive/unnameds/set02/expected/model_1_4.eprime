language ESSENCE' 1.0

given n: int
find s_Occurrence: matrix indexed by [int(1..n)] of bool
find s_ExplicitVarSizeWithFlags_Flags: matrix indexed by [int(1..1 + (n - 1))] of bool
find s_ExplicitVarSizeWithFlags_Values: matrix indexed by [int(1..1 + (n - 1))] of int(1..n)
such that
    and([[s_Occurrence[[q2, q1 + 1, q1; int(0..2)][toInt(q2 = q1) + 2 * toInt(q2 = q1 + 1)]] | q2 : int(1..n)] <=lex
         [s_Occurrence[q2] | q2 : int(1..n)]
             | q1 : int(1..n - 1)]),
    and([s_ExplicitVarSizeWithFlags_Flags[q2 + 1] ->
         s_ExplicitVarSizeWithFlags_Values[q2] < s_ExplicitVarSizeWithFlags_Values[q2 + 1]
             | q2 : int(1..1 + (n - 1) - 1)]),
    and([s_ExplicitVarSizeWithFlags_Flags[q3] = false -> s_ExplicitVarSizeWithFlags_Values[q3] = 1
             | q3 : int(1..1 + (n - 1))]),
    and([s_ExplicitVarSizeWithFlags_Flags[q4 + 1] -> s_ExplicitVarSizeWithFlags_Flags[q4]
             | q4 : int(1..1 + (n - 1) - 1)]),
    and([s_ExplicitVarSizeWithFlags_Flags[q8] -> s_Occurrence[s_ExplicitVarSizeWithFlags_Values[q8]]
             | q8 : int(1..1 + (n - 1))]),
    and([s_Occurrence[q9] ->
         or([s_ExplicitVarSizeWithFlags_Flags[q11] /\ s_ExplicitVarSizeWithFlags_Values[q11] = q9
                 | q11 : int(1..1 + (n - 1))])
             | q9 : int(1..n)])

