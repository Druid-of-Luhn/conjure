language ESSENCE' 1.0

given s: int
given fin1: int
given fin2: int
given fin3: int
given nums_Explicit: matrix indexed by [int(1..fin1)] of int(fin2..fin3)
letting let1 be fin1
letting let2 be fin2
letting let3 be fin3
find x_ExplicitVarSizeWithMarker_Marker: int(0..let1)
find x_ExplicitVarSizeWithMarker_Values: matrix indexed by [int(1..let1)] of int(let2..let3)
find x_Occurrence: matrix indexed by [int(let2..let3)] of bool
such that
    and([q12 <= x_ExplicitVarSizeWithMarker_Marker ->
         or([nums_Explicit[q14] = x_ExplicitVarSizeWithMarker_Values[q12] | q14 : int(1..fin1)])
             | q12 : int(1..let1)]),
    s =
    sum([toInt(q10 <= x_ExplicitVarSizeWithMarker_Marker) * x_ExplicitVarSizeWithMarker_Values[q10]
             | q10 : int(1..let1)]),
    and([q1 + 1 <= x_ExplicitVarSizeWithMarker_Marker ->
         x_ExplicitVarSizeWithMarker_Values[q1] < x_ExplicitVarSizeWithMarker_Values[q1 + 1]
             | q1 : int(1..let1 - 1)]),
    and([q2 > x_ExplicitVarSizeWithMarker_Marker -> x_ExplicitVarSizeWithMarker_Values[q2] = let2 | q2 : int(1..let1)]),
    1 <= x_ExplicitVarSizeWithMarker_Marker,
    x_ExplicitVarSizeWithMarker_Marker <= let1,
    1 <= sum([toInt(x_Occurrence[q4]) | q4 : int(let2..let3)]),
    sum([toInt(x_Occurrence[q4]) | q4 : int(let2..let3)]) <= let1,
    and([x_Occurrence[q5] ->
         or([q7 <= x_ExplicitVarSizeWithMarker_Marker /\ x_ExplicitVarSizeWithMarker_Values[q7] = q5
                 | q7 : int(1..let1)])
             | q5 : int(let2..let3)]),
    and([q9 <= x_ExplicitVarSizeWithMarker_Marker -> x_Occurrence[x_ExplicitVarSizeWithMarker_Values[q9]]
             | q9 : int(1..let1)])

