language ESSENCE' 1.0

given a: int
find x_ExplicitVarSizeWithFlags_Flags:
        matrix indexed by [int(1..2)] of int(0..min([2, 1 + (a - 1); int(1..2)]))
find x_ExplicitVarSizeWithFlags_Values:
        matrix indexed by [int(1..2)] of int(1..a)
such that
    x_ExplicitVarSizeWithFlags_Flags[2] > 0 ->
    x_ExplicitVarSizeWithFlags_Values[1] < x_ExplicitVarSizeWithFlags_Values[2],
    and([x_ExplicitVarSizeWithFlags_Flags[q2] = 0 ->
         x_ExplicitVarSizeWithFlags_Values[q2] = 1
             | q2 : int(1..2)]),
    x_ExplicitVarSizeWithFlags_Flags[2] > 0 ->
    x_ExplicitVarSizeWithFlags_Flags[1] > 0,
    2 = sum([x_ExplicitVarSizeWithFlags_Flags[q5] | q5 : int(1..2)])

