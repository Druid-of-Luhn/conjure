language ESSENCE' 1.0

given s: int
given fin1: int
given fin2: int
given fin3: int
given nums_Explicit: matrix indexed by [int(1..fin1)] of int(fin2..fin3)
letting let1 be fin1
letting let2 be fin2
letting let3 be fin3
find x_Occurrence: matrix indexed by [int(let2..let3)] of bool
find x_ExplicitVarSizeWithFlags_Flags: matrix indexed by [int(1..let1)] of bool
find x_ExplicitVarSizeWithFlags_Values:
        matrix indexed by [int(1..let1)] of int(let2..let3)
find x_ExplicitVarSizeWithDummy:
        matrix indexed by [int(1..let1)] of int(let2..let3 + 1)
such that
    and([x_Occurrence[q30] -> or([nums_Explicit[q32] = q30 | q32 : int(1..fin1)])
             | q30 : int(let2..let3)]),
    s =
    sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q24]) *
         x_ExplicitVarSizeWithFlags_Values[q24]
             | q24 : int(1..let1)]),
    1 <= sum([toInt(x_Occurrence[q1]) | q1 : int(let2..let3)]),
    sum([toInt(x_Occurrence[q1]) | q1 : int(let2..let3)]) <= let1,
    and([x_ExplicitVarSizeWithFlags_Flags[q2 + 1] ->
         x_ExplicitVarSizeWithFlags_Values[q2] <
         x_ExplicitVarSizeWithFlags_Values[q2 + 1]
             | q2 : int(1..let1 - 1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q3] = false ->
         x_ExplicitVarSizeWithFlags_Values[q3] = let2
             | q3 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q4 + 1] ->
         x_ExplicitVarSizeWithFlags_Flags[q4]
             | q4 : int(1..let1 - 1)]),
    1 <= sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q5]) | q5 : int(1..let1)]),
    sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q5]) | q5 : int(1..let1)]) <= let1,
    and([x_ExplicitVarSizeWithFlags_Flags[q26] ->
         x_Occurrence[x_ExplicitVarSizeWithFlags_Values[q26]]
             | q26 : int(1..let1)]),
    and([x_Occurrence[q27] ->
         or([x_ExplicitVarSizeWithFlags_Flags[q29] /\
             x_ExplicitVarSizeWithFlags_Values[q29] = q27
                 | q29 : int(1..let1)])
             | q27 : int(let2..let3)]),
    and([x_ExplicitVarSizeWithDummy[q7] < x_ExplicitVarSizeWithDummy[q7 + 1] \/
         x_ExplicitVarSizeWithDummy[q7] = let3 + 1
             | q7 : int(1..let1 - 1)]),
    and([x_ExplicitVarSizeWithDummy[q8] = let3 + 1 ->
         x_ExplicitVarSizeWithDummy[q8 + 1] = let3 + 1
             | q8 : int(1..let1 - 1)]),
    1 <=
    sum([toInt(x_ExplicitVarSizeWithDummy[q9] != let3 + 1) | q9 : int(1..let1)]),
    sum([toInt(x_ExplicitVarSizeWithDummy[q9] != let3 + 1) | q9 : int(1..let1)]) <=
    let1,
    and([x_ExplicitVarSizeWithDummy[q12] != let3 + 1 ->
         x_Occurrence[x_ExplicitVarSizeWithDummy[q12]]
             | q12 : int(1..let1)]),
    and([x_Occurrence[q13] ->
         or([x_ExplicitVarSizeWithDummy[q15] != let3 + 1 /\
             x_ExplicitVarSizeWithDummy[q15] = q13
                 | q15 : int(1..let1)])
             | q13 : int(let2..let3)]),
    and([x_ExplicitVarSizeWithDummy[q17] != let3 + 1 ->
         or([x_ExplicitVarSizeWithFlags_Flags[q19] /\
             x_ExplicitVarSizeWithFlags_Values[q19] = x_ExplicitVarSizeWithDummy[q17]
                 | q19 : int(1..let1)])
             | q17 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q21] ->
         or([x_ExplicitVarSizeWithDummy[q23] != let3 + 1 /\
             x_ExplicitVarSizeWithDummy[q23] = x_ExplicitVarSizeWithFlags_Values[q21]
                 | q23 : int(1..let1)])
             | q21 : int(1..let1)])

