language ESSENCE' 1.0

given s: int
given fin1: int
given fin2: int
given fin3: int
given nums_Explicit: matrix indexed by [int(1..fin1)] of int(fin2..fin3)
letting let1 be fin1
letting let2 be fin2
letting let3 be fin3
find x_ExplicitVarSizeWithDummy:
        matrix indexed by [int(1..let1)] of int(let2..let3, 1 + max(`int(let2..let3)`))
find x_Occurrence: matrix indexed by [int(let2..let3)] of bool
find x_ExplicitVarSizeWithFlags_Flags: matrix indexed by [int(1..let1)] of bool
find x_ExplicitVarSizeWithFlags_Values:
        matrix indexed by [int(1..let1)] of int(let2..let3)
such that
    and([x_ExplicitVarSizeWithDummy[q43] !=
         max([q46 | q46 : int(let2..let3, 1 + max([q47 | q47 : int(let2..let3)]))])
         ->
         or([nums_Explicit[q45] = x_ExplicitVarSizeWithDummy[q43] | q45 : int(1..fin1)])
             | q43 : int(1..let1)]),
    s = sum([toInt(x_Occurrence[i]) * i | i : int(let2..let3)]),
    and([x_ExplicitVarSizeWithDummy[q1] < x_ExplicitVarSizeWithDummy[q1 + 1] \/
         x_ExplicitVarSizeWithDummy[q1] = 1 + max([q11 | q11 : int(let2..let3)])
             | q1 : int(1..let1 - 1)]),
    and([x_ExplicitVarSizeWithDummy[q2] = 1 + max([q12 | q12 : int(let2..let3)]) ->
         x_ExplicitVarSizeWithDummy[q2 + 1] = 1 + max([q13 | q13 : int(let2..let3)])
             | q2 : int(1..let1 - 1)]),
    1 <=
    sum([toInt(x_ExplicitVarSizeWithDummy[q3] !=
               1 + max([q14 | q14 : int(let2..let3)]))
             | q3 : int(1..let1)]),
    sum([toInt(x_ExplicitVarSizeWithDummy[q3] !=
               1 + max([q15 | q15 : int(let2..let3)]))
             | q3 : int(1..let1)])
    <= let1,
    1 <= sum([toInt(x_Occurrence[q5]) | q5 : int(let2..let3)]),
    sum([toInt(x_Occurrence[q5]) | q5 : int(let2..let3)]) <= let1,
    and([x_Occurrence[q33] ->
         or([x_ExplicitVarSizeWithDummy[q35] !=
             max([q36 | q36 : int(let2..let3, 1 + max([q37 | q37 : int(let2..let3)]))])
             /\ x_ExplicitVarSizeWithDummy[q35] = q33
                 | q35 : int(1..let1)])
             | q33 : int(let2..let3)]),
    and([x_ExplicitVarSizeWithDummy[q39] !=
         max([q40 | q40 : int(let2..let3, 1 + max([q41 | q41 : int(let2..let3)]))])
         -> x_Occurrence[x_ExplicitVarSizeWithDummy[q39]]
             | q39 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q6 + 1] ->
         x_ExplicitVarSizeWithFlags_Values[q6] <
         x_ExplicitVarSizeWithFlags_Values[q6 + 1]
             | q6 : int(1..let1 - 1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q7] = false ->
         x_ExplicitVarSizeWithFlags_Values[q7] = let2
             | q7 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q8 + 1] ->
         x_ExplicitVarSizeWithFlags_Flags[q8]
             | q8 : int(1..let1 - 1)]),
    1 <= sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q9]) | q9 : int(1..let1)]),
    sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q9]) | q9 : int(1..let1)]) <= let1,
    and([x_ExplicitVarSizeWithFlags_Flags[q17] ->
         or([x_ExplicitVarSizeWithDummy[q19] !=
             max([q20 | q20 : int(let2..let3, 1 + max([q21 | q21 : int(let2..let3)]))])
             /\ x_ExplicitVarSizeWithDummy[q19] = x_ExplicitVarSizeWithFlags_Values[q17]
                 | q19 : int(1..let1)])
             | q17 : int(1..let1)]),
    and([x_ExplicitVarSizeWithDummy[q23] !=
         max([q26 | q26 : int(let2..let3, 1 + max([q27 | q27 : int(let2..let3)]))])
         ->
         or([x_ExplicitVarSizeWithFlags_Flags[q25] /\
             x_ExplicitVarSizeWithFlags_Values[q25] = x_ExplicitVarSizeWithDummy[q23]
                 | q25 : int(1..let1)])
             | q23 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q29] ->
         x_Occurrence[x_ExplicitVarSizeWithFlags_Values[q29]]
             | q29 : int(1..let1)]),
    and([x_Occurrence[q30] ->
         or([x_ExplicitVarSizeWithFlags_Flags[q32] /\
             x_ExplicitVarSizeWithFlags_Values[q32] = q30
                 | q32 : int(1..let1)])
             | q30 : int(let2..let3)])

