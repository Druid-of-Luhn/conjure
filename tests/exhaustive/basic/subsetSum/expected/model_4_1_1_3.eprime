language ESSENCE' 1.0

given s: int
given fin1: int
given fin2: int
given fin3: int
given nums_Occurrence: matrix indexed by [int(fin2..fin3)] of bool
letting let1 be fin1
letting let2 be fin2
letting let3 be fin3
find x_ExplicitVarSizeWithFlags_Flags: matrix indexed by [int(1..let1)] of bool
find x_ExplicitVarSizeWithFlags_Values: matrix indexed by [int(1..let1)] of int(let2..let3)
find x_Occurrence: matrix indexed by [int(let2..let3)] of bool
find x_ExplicitVarSizeWithMarker_Marker: int(0..let1)
find x_ExplicitVarSizeWithMarker_Values: matrix indexed by [int(1..let1)] of int(let2..let3)
such that
    and([x_ExplicitVarSizeWithFlags_Flags[q29] -> nums_Occurrence[x_ExplicitVarSizeWithFlags_Values[q29]]
             | q29 : int(1..let1)]),
    s = sum([toInt(x_Occurrence[i]) * i | i : int(let2..let3)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q1 + 1] ->
         x_ExplicitVarSizeWithFlags_Values[q1] < x_ExplicitVarSizeWithFlags_Values[q1 + 1]
             | q1 : int(1..let1 - 1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q2] = false -> x_ExplicitVarSizeWithFlags_Values[q2] = let2
             | q2 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q3 + 1] -> x_ExplicitVarSizeWithFlags_Flags[q3] | q3 : int(1..let1 - 1)]),
    1 <= sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q4]) | q4 : int(1..let1)]),
    sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q4]) | q4 : int(1..let1)]) <= let1,
    1 <= sum([toInt(x_Occurrence[q6]) | q6 : int(let2..let3)]),
    sum([toInt(x_Occurrence[q6]) | q6 : int(let2..let3)]) <= let1,
    and([x_Occurrence[q23] ->
         or([x_ExplicitVarSizeWithFlags_Flags[q25] /\ x_ExplicitVarSizeWithFlags_Values[q25] = q23
                 | q25 : int(1..let1)])
             | q23 : int(let2..let3)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q27] -> x_Occurrence[x_ExplicitVarSizeWithFlags_Values[q27]]
             | q27 : int(1..let1)]),
    and([q7 + 1 <= x_ExplicitVarSizeWithMarker_Marker ->
         x_ExplicitVarSizeWithMarker_Values[q7] < x_ExplicitVarSizeWithMarker_Values[q7 + 1]
             | q7 : int(1..let1 - 1)]),
    and([q8 > x_ExplicitVarSizeWithMarker_Marker -> x_ExplicitVarSizeWithMarker_Values[q8] = let2 | q8 : int(1..let1)]),
    1 <= x_ExplicitVarSizeWithMarker_Marker,
    x_ExplicitVarSizeWithMarker_Marker <= let1,
    and([q11 <= x_ExplicitVarSizeWithMarker_Marker ->
         or([x_ExplicitVarSizeWithFlags_Flags[q13] /\
             x_ExplicitVarSizeWithFlags_Values[q13] = x_ExplicitVarSizeWithMarker_Values[q11]
                 | q13 : int(1..let1)])
             | q11 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q15] ->
         or([q17 <= x_ExplicitVarSizeWithMarker_Marker /\
             x_ExplicitVarSizeWithMarker_Values[q17] = x_ExplicitVarSizeWithFlags_Values[q15]
                 | q17 : int(1..let1)])
             | q15 : int(1..let1)]),
    and([q19 <= x_ExplicitVarSizeWithMarker_Marker -> x_Occurrence[x_ExplicitVarSizeWithMarker_Values[q19]]
             | q19 : int(1..let1)]),
    and([x_Occurrence[q20] ->
         or([q22 <= x_ExplicitVarSizeWithMarker_Marker /\ x_ExplicitVarSizeWithMarker_Values[q22] = q20
                 | q22 : int(1..let1)])
             | q20 : int(let2..let3)])

